---
title: "Groupwork_2_Group6"
author: "Luca Wirths, Lars Wenger, Josua Reich, Abishan Arumugavel "
date: "2023-05-21"
output:
  html_document:
    toc: yes
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Table of content {.tabset}

## Preparations


### Import Modules
```{r, include=FALSE}
#install.packages("readr")
#install.packages("dplyr")
#install.packages("dlookr")
#install.packages("naniar")
#install.packages("UpSetR")
#install.packages("ggplot2")
#install.packages("tidyr")
#install.packages("mice")
#install.packages("purrr")
#install.packages("scales")

library(readr)
library(dplyr)
library(dlookr)
library(naniar)
#library(UpSetR)
library(ggplot2)
library(tidyr)
#library(mice)
library(purrr)
#library(scales)
library(Boruta)
library(DescTools)
#library(caret)
# Call other necessary libraries 
library(data.table)
#library(writexl)
library(h2o)

```


### Import Data
```{r}
load("data_wage.RData")
data_wage <- data #copy of dataset
set.seed(8)
```

## Analyse Data

```{r}
overview(data)
summary(data)
```

In the data are 10809 observations of 78 variables. 

Most of the respondents in the dataset are male (9135). Rest of it are female (1571), prefered "not to say" (72) or did "self-describe" (31). Thus the men are strongly overrepresented. However, this is probably due to the industry, where a larger proportion of men are employed. A similar overrepresentation can be seen in the country of origin. There is also a clear majority there with USA (2505) and India (1576).
The dataset is somewhat more balanced with regard to the age of the participants. Most participants are between 25-29 years old (3008), but the remaining age groups are also well represented.
It is also clear that about half of the participants have a master's degree (5209). However, there is also a good proportion of participants with a bachelor's degree (2990) or a doctorate (1869).
Most participants have studied "Computer Science" (4239), "Engineering" (1704) or "Mathematics or Statistics" (1545). 
In terms of job title, there are different designations with "Data Scientist" (2505), "Software Engineer" (1800), "Student" (1588) and "Data Analyst" (1022).
The majority of the participants still have little professional experience. Thus, more than half of the participants have less than 3 years of experience.


### Check data

We now investigated the data on plausability. 
To have a better feeling and see more in detail how the feature is distributed we show here the plot_outlier, which gives us a boxplot and a histogram with and without outliers.

```{r,echo=FALSE}
#Let's visualize all columnns with and without outliers
data %>%
  plot_outlier(col="aquamarine3",diagnose_outlier(data['wage']) %>%
                 filter(outliers_ratio >= 0.5) %>%          # dplyr
                 select(variables) %>%
                 unlist())

```

We see that without the outliers the standard distribution is better.
We see the problem in the surveys that both the job description and the industry can indicate that you are a student. How to handle this was probably not immediately clear to all respondents.
That's why we check how plausible the information in the survey can be. On the one hand, we look at how many people who are not students have stated that they do not earn anything. We also look at how many students stated that they earn more than 150,000. Both are combinations that we do not consider plausible. We see that there are such entries and therefore assume that the outliers are partly due to incorrect entries.


```{r, echo=FALSE}
# Check how many non-students have wage = 0 
num_rows_1 <- nrow(data[data$wage == 0 & data$job_role != "Student" | data$wage == 0 & data$industry != "I am a student", ])
print(paste("Number of **Non** student's, with wage 0:", num_rows_1))

# Check how many students have wage > 150'000
num_rows_2 <- nrow(data[data$wage > 150000 & data$job_role == "Student" | data$wage > 150000 & data$industry != "I am a student", ])
print(paste("Number of student's, with wage more than 150,000:", num_rows_2))
```

We see those two possibilities to now ether delete those entries or we use an outlierhandling and give them a wage.

Since we have already looked at the outlierdistribution above, we think it is better to use the outlierhandling.
So we create now the standard function to replace the outliers with the 10th and 90th percentile value of that wage feature. The default values for the outlierhandling would be 5/95% but, we have a little below 10% of data with "0$" as wage, so we had to change it to 10/90% values.

```{r,echo=FALSE}
outlier <- function(x){
  quantiles <- quantile(x, c(.1, .9))
  x[x < quantiles[1]] <- quantiles[1]
  x[x > quantiles[2]] <- quantiles[2]
  x
}   
```

In the next step, we apply the outlier function. For this, we use the map_df function. This allows us to apply a function to each element of a list or atomic vector.

```{r}

#Use function outlier for the dataset
data['wage'] <- map_df(data['wage'], outlier)
```

With this outlierhandling, the students now make around 3200 $ / year. Which we think is a plausible value.



### Target feature wage

Let us check the target feature. It does not really make sense, if you think why are there people with that low of an income. But with all the different costs of living it makes sense.

```{r}
# Let's check our dependent variable "wage"
summary(data$wage)
ggplot(data, aes(x = wage)) + 
  geom_histogram(fill="aquamarine3", color = "black") +
  labs(title = "Histogram of the wages") +
  theme(legend.position="none")
```

```{r}

data_remove <- data[!(data$wage == 0 & data$job_role != "Student" | data$wage == 0 & data$industry != "I am a student"), ]





```





### Data selection

To the most important part now:
For our model we want to use only the relevants features.
So help us select the right features, we use the boruta algorithm. 



#### TEST features
Here we see the first Boruta results. 

```{r, echo=FALSE,message=FALSE,warning=FALSE}
test_data <- data
str(test_data)
# boruta_output <- Boruta(wage~., data = test_data, doTrace=2)
# boruta_signif <- getSelectedAttributes(boruta_output, withTentative = TRUE)
# print(boruta_signif)
```
```{r, echo=FALSE,message=FALSE,warning=FALSE}
# plot(boruta_output, cex.axis=.7, las=2, xlab="", main="Variable Importance") 
```
Since it was not finished after one run, we now create a subset only with the remaining 53 features.
The 53 features are: (Evtl am ende lÃ¶schen da die Anzeige oben ist.. )
 [1] "age"
 [2] "country"
 [3] "education"
 [4] "undergraduate_major"
 [5] "job_role"
 [6] "industry"
 [7] "years_experience"
 [8] "ML_atwork"
 [9] "Activities_Analyze.and.understand.data.to.influence.product.or.business.decisions"
[10] "Activities_Build.and.or.run.a.machine.learning.service.that.operationally.improves.my.product.or.workflows"
[11] "Activities_Build.and.or.run.the.data.infrastructure.that.my.business.uses.for.storing..analyzing..and.operationalizing.data"
[12] "Activities_Build.prototypes.to.explore.applying.machine.learning.to.new.areas"
[13] "Activities_Do.research.that.advances.the.state.of.the.art.of.machine.learning"
[14] "Activities_None.of.these.activities.are.an.important.part.of.my.role.at.work"
[15] "Notebooks_Google.Colab"
[16] "Notebooks_Google.Cloud.Datalab"
[17] "cloud_Amazon.Web.Services..AWS."
[18] "cloud_Alibaba.Cloud"
[19] "cloud_I.have.not.used.any.cloud.providers"
[20] "Programming_Python"
[21] "Programming_R"
[22] "Programming_SQL"
[23] "Programming_Java"
[24] "Programming_C.C.."
[25] "Programming_MATLAB"
[26] "Programming_language_used_most_often"
[27] "ML_framework_Scikit.Learn"
[28] "ML_framework_TensorFlow"
[29] "ML_framework_Keras"
[30] "ML_framework_Spark.MLlib"
[31] "ML_framework_Caret"
[32] "ML_framework_Xgboost"
[33] "ML_framework_randomForest"
[34] "ML_framework_None"
[35] "Visualization_ggplot2"
[36] "Visualization_Matplotlib"
[37] "Visualization_Shiny"
[38] "Visualization_Plotly"
[39] "Visualization_None"
[40] "percent_actively.coding"
[41] "How.long.have.you.been.writing.code.to.analyze.data."
[42] "For.how.many.years.have.you.used.machine.learning.methods..at.work.or.in.school.."
[43] "Do.you.consider.yourself.to.be.a.data.scientist."
[44] "data_Categorical.Data"
[45] "data_Image.Data"
[46] "data_Numerical.Data"
[47] "data_Tabular.Data"
[48] "data_text.Data"
[49] "data_Time.Series.Data"
[50] "explainability.model_Examine.individual.model.coefficients"
[51] "explainability.model_examine.feature.correlations"
[52] "explainability.model_Examine.feature.importances"
[53] "explainability.model_None.I.do.not.use.these.model.explanation.techniques"  


```{r, echo=FALSE,message=FALSE,warning=FALSE}
#create new dataframe
new_data <- data[,c(2,3,4,5,6,7,8,9,10,11,12,13,14,15,17,19,23,26,27,28,29,30,32,35,36,40,41,42,43,45,47,48,49,50,51,52,54,55,56,57,58,59,60,61,64,65,67,68,69,71,72,73,77,78)]

# run Boruta again now with all data to the selected features
# boruta_output <- Boruta(wage~., data = new_data, doTrace=2)
# boruta_signif <- getSelectedAttributes(boruta_output, withTentative = TRUE)
# print(boruta_signif)

```
```{r}
# plot(boruta_output, cex.axis=.7, las=2, xlab="", main="Variable Importance") 
```

with this output we see, that the variable Google Colab is not that important so we remove it. 

```{r}
new_data <- new_data %>% select(-Notebooks_Google.Colab)
```

With that we we have no our final features. We these we can build our model.

## ML part

### Find best ML

We use H20 AutoML to get the best ML-technique. It creates different machine learning algorithms, and compares them automatically.

 Installing & initializing H20. 
```{r H20Cluster} 

# Installing & initializing H20. In case you have past installations, you should run 
# lines 37-44. If this is the first time installing, you can only run lines 43-44.
#if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
#if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
pkgs <- c("RCurl","jsonlite")
for (pkg in pkgs) {
  if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}
#install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/latest_stable_R")))

library(h2o)





# Initialize H2O cluster
h2o.init()


# Specify the column containing the dependent feature
dep_var <- "wage"


# Identify the categorical variables in the dataset
cat_cols <- c()
for (col in names(new_data)) {
  if (class(new_data[[col]]) == "factor" | typeof(new_data[[col]]) == "character") {
    cat_cols <- c(cat_cols, col)
  }
}

# Convert the categorical variables to factors
new_data[cat_cols] <- lapply(new_data[cat_cols], factor)


df <- as.h2o(new_data)


# Split dataset into training and test sets
set.seed(8)
splits <- h2o.splitFrame(df, ratios = c(0.8))
train <- splits[[1]]
test <- h2o.importFile("our_data.csv")
#h2o.importFile("our_data.csv")
#our_data <- read.csv("our_data.csv")

```

# Run AutoML

```{r name=automl}
automl <- h2o.automl(
  x = setdiff(colnames(df), dep_var), # independent variables
  y = dep_var, # dependent variable
  training_frame = train,
  max_runtime_secs = 600, # maximum time in seconds for AutoML to run
  seed = 12 # set seed for reproducibility
)


  # View leaderboard of models generated by AutoML
lb <- automl@leaderboard
print(lb, n = nrow(lb)) 
```

We see that the best model which is not a Stacked Ensemble is a GBM model. The Gradient Boosting Machine (GBM) is a machine learning model that combines multiple weak prediction models, typically decision trees, to create a strong predictive model. It does this by iteratively fitting new models to the residuals of the previous models, effectively focusing on the mistakes made by the previous models and minimizing them in subsequent iterations. The final prediction is obtained by aggregating the predictions of all the models, with each model assigned a weight based on its performance.

```{r}
# Find the best performing model per RMSE criteria and explore it.
best_RMSE <- h2o.get_best_model(automl, criterion = "RMSE", algorithm = "GBM")   # Best model per the RSME indicator. 
best_RMSE                                                    # Let's explore the best perfroming model 
```


Interesting is the RMSE, which is still 27'186 dollar which means, that every output has a deviation of +/- 27'186$ which is not that great for predicting wage. 

```{r}

# Get training timing info LARS DO WE NEED THAT? I dont think so
trainingInfo <- automl@training_info
trainingInfo

```
```{r}
# Predictions and performance on our test sample. 
# Obtain the predictions for our test subset
pred_best_RMSE <- h2o.predict(best_RMSE, test)
```
```{r}
predictions <- as.data.table(pred_best_RMSE)
predictions
```


```{r}

## Explanation
# Global explanations -- explains the hole model

# Explain leader model & compare with all AutoML models
exp_automl <- h2o.explain(best_RMSE, test) 
print(exp_automl) 

# Some explainations concerning the plots: 
# The green lines or dots on the PDP show the average response versus feature value with error bars.  
# The grey histogram shows the number of instances for each range of feature values. 
# For the monthly income plot plot, we can see that the average leaving rate decreases
# with the montly income, but also that the data becomes increasingly sparse for larger interest rates.


# Local explanations -- Explain a specific unit (i.e. obtain explanations for 
# a single person in the sample). 

# In the following step, we explain the behavior of a model or group of models 
# with respect to a single row of data. By using the h2o.explain_row() function, 
# the outputs would be: 
#  * SHAP Contribution Plot (for the top tree-based model in AutoML)
#  * Individual Conditional Expectation (ICE) Plots

```

## Future Salaries

### Abishan

```{r}
#LARS fÃ¼r was ist das hier? braucht es aus meiner sicht nicht.
GBM_auc <- h2o.get_best_model(automl, algorithm = "GBM")
```


### Abishan
```{r}
Abishan <- h2o.explain_row(best_RMSE, test, row_index = 1)
Abishan[1]
```
Wage is influenced by various factors. For a high wage, being in Switzerland, working in the "Other" industry, using SQL, and having a business discipline undergraduate major are important. For a low wage, being a student, uncertain ML involvement, 0-1 years of experience, and an age of 22-24 are significant.
These factors are not surprising and are therefore plausible.



### Josua

```{r}
Josua <- h2o.explain_row(best_RMSE, test, row_index = 2)
Josua[1]
```

According to our model, important parameters for a high wage include being in Switzerland, working in the "Other" industry, using SQL programming language, and having a business discipline undergraduate major. For a low wage, being a student, not working with machine learning, having 0-1 years of experience, and writing code for 1-2 years are significant factors. 
These factors are not surprising and are therefore plausible.

### Lars

```{r}
Lars <- h2o.explain_row(best_RMSE, test, row_index = 3)
Lars[1]
```

For a higher wage, being in Switzerland, working in the "Other" industry, and having a business discipline undergraduate major are important. For a lower wage, being a student, not working with machine learning, having 0-1 years of experience, and falling within the age range of 25-29 are significant factors. These findings are based on the ML model, and other factors can also impact wages.

### Luca

```{r}
Luca <- h2o.explain_row(best_RMSE, test, row_index = 4)
Luca[1]
```

Wage is influenced by various factors. For a higher wage, being in Switzerland, working in the "Other" job role, and having well-established involvement in machine learning at work are important. For a lower wage, being in the age range of 25-29, having 3-4 years of experience, and not being engaged in activities for building prototypes are significant. These findings are based on the ML model, and other factors can also impact wages.

## Conclusion

Across all four trials, there are clear indications of factors that are relevant to wages. Country is a very strong determinant. Additionally, being a student is an important factor. We can also observe the biggest difference in our statements since Luca was the only one who did not mention being in the industry, instead stating "I am a student." As a result, Luca earns three times as much as the rest of us. Age is also a relevant factor; based on our information (everyone under 30 years of age), it has a negative impact on wages. The job role assigned as "Other" is the only strong factor that is not clearly understandable. Nevertheless, we are fundamentally very satisfied with our model, as the factors it considers are plausible and comprehensible. We will be happy once we can settle as students and immediately start earning three times more than before ;) 

# LARS wollen wir das hier auch machen? 
### What kind of challenges may a company face if it would use your model in their daily business, in particular in regard to ethical challenges and moral obligations companies have?

If a company choose, to use our model, there would be a fault rate of around 30%. So it depends on the amount of loan, but there is a chance, to loose a lot of money, if it does not pay out.

With our model, the decision, if somebody get a loan or not, would be only based on the numbers and not on the purpose. If for example somebody urgently needs money to pay an important medical surgery in order to survive the cancer, the company only will decide, if they get the money based on their income, ... In a ethical way, you have to give the money to this person, because otherwise the person who needs the money will die. This is an ethical challenge and also an moral obligations a company has with our model.

To get back to our fault rate of 30% there is a chance, that in such a situation, the person who would be in charge to get the loan, would not get the loan and therefor can not pay the surgery.

But there would also be the chance, that a person who use the money for their criminal businesses, would get the loan. Because our model only analyse the raw numbers and does not care about the status of the person in the civilization.

### Can you think of a way how companies can overcome or at least mitigate the issues that you described above?

They just should not use our model primary. They should use it as an consulting model, together with other analyzing tools. For example a background check of the customer or a personal interview with them. This way, the company can better decide, if the person needs the money and they can base their decisions on more than just one tool.

## SessionInfo
```{r,echo=FALSE}
sessionInfo()
```